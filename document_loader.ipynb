{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    '25',\n",
    "    '261',\n",
    "    '306',\n",
    "    '313',\n",
    "    '352',\n",
    "    '359',\n",
    "    '360',\n",
    "    '381',\n",
    "    '603',\n",
    "    '654',\n",
    "    '655',\n",
    "    '656',\n",
    "    '662',\n",
    "    '664',\n",
    "    '677',\n",
    "    '683',\n",
    "    '714',\n",
    "    '724',\n",
    "    '749',\n",
    "    '783'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_join(soup):\n",
    "    text_parts = []\n",
    "    for element in soup.descendants:\n",
    "        if element.name == 'em':\n",
    "            # Добавляем текст внутри <em> без переноса строки\n",
    "            if element.string:\n",
    "                text_parts.append(' ' + element.string)\n",
    "        elif isinstance(element, str):\n",
    "            # Добавляем текстовые ноды с переносом строки, если они не внутри <em>\n",
    "            stripped_string = element.strip()\n",
    "            if stripped_string:\n",
    "                # Проверяем, не является ли предыдущий элемент <em> для избежания лишних переносов\n",
    "                if text_parts and text_parts[-1].endswith('\\n'):\n",
    "                    text_parts[-1] += stripped_string\n",
    "                else:\n",
    "                    text_parts.append(stripped_string + '\\n')\n",
    "        elif element.name in ['p', 'div']:\n",
    "            # Явное добавление переноса строки после параграфов и дивов\n",
    "            text_parts.append('\\n')\n",
    "\n",
    "    return ''.join(text_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Регулярное выражение для поиска паттернов с учетом неразрывного пробела\n",
    "    pattern = r'\\(J\\d+(\\.\\d+)?\\)|J\\d+(\\.\\d+)?'\n",
    "    # Замена найденных паттернов на пустую строку\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_element_by_id(data,id):\n",
    "    for i in range(len(data)):\n",
    "        if(data[i]['id']==id):\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diseases_in_content(data):\n",
    "    content = data[find_by_element_by_id(data,'doc_1')]['content']\n",
    "    soup = bs4.BeautifulSoup(content)\n",
    "    related_diseases = 'Особенности кодирования заболевания'.lower()\n",
    "\n",
    "    current_element = None\n",
    "    for h in soup.findAll('h2'):\n",
    "        if(related_diseases in h.text.lower()):\n",
    "            current_element = h\n",
    "            break\n",
    "    \n",
    "    current_element = current_element.findNext()\n",
    "    text = ''\n",
    "    while(current_element.name != 'h2'):\n",
    "        text += f'{current_element.text}\\n'\n",
    "        current_element = current_element.findNext()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(id):\n",
    "    url = f'https://apicr.minzdrav.gov.ru/api.ashx?op=GetClinrec2&id={id}&ssid=undefined'\n",
    "    request = requests.get(url)\n",
    "\n",
    "    data = request.json()['obj']['sections']\n",
    "\n",
    "    start = 'Диагностика'.lower()\n",
    "    end = 'Дополнительная информация'.lower()\n",
    "    title = 'Титульный лист'.lower()\n",
    "\n",
    "    start_index = None\n",
    "    end_index = None\n",
    "    title_index = None\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        d = data[i]\n",
    "        name = d['title'].lower()\n",
    "        if(start in name):\n",
    "            start_index = i\n",
    "        if(end in name):\n",
    "            end_index = i\n",
    "        if(title in name):\n",
    "            title_index = i\n",
    "\n",
    "        if(end_index != None and start_index != None and title_index != None):\n",
    "            break\n",
    "    \n",
    "    text = ''\n",
    "    for i in range(start_index,end_index+1):\n",
    "        d = data[i]\n",
    "        title = d['title']\n",
    "\n",
    "        soup = bs4.BeautifulSoup(d['content'])\n",
    "        content = ' \\n'.join(soup.stripped_strings)\n",
    "        text += f'''\n",
    "        {title}\\n\n",
    "        {content}\\n\n",
    "        '''\n",
    "\n",
    "    related_diseases_text = ''\n",
    "\n",
    "    related_diseases_index = find_by_element_by_id(data,'doc_crat_info_1_4')\n",
    "\n",
    "    if(related_diseases_index!=None):\n",
    "        d = data[related_diseases_index]\n",
    "        soup = bs4.BeautifulSoup(d['content'])\n",
    "        related_diseases_text = soup.getText()\n",
    "    else:\n",
    "        print('Related text was not found. Using content')\n",
    "        related_diseases_text = find_diseases_in_content(data)\n",
    "\n",
    "\n",
    "    d = data[title_index]\n",
    "    main_disease = d['data'][0]['content']\n",
    "\n",
    "    related_diseases_text = clean_text(related_diseases_text)\n",
    "\n",
    "    cr_info = f'''\n",
    "<id>{id}</id>:\n",
    "<title>{main_disease}</title>\n",
    "    ''' \n",
    "\n",
    "\n",
    "    return text,cr_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,info = parse_document(381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<id>381</id>:\n",
      "<title>Бронхит</title>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 done\n",
      "Related text was not found. Using content\n",
      "261 done\n",
      "306 done\n",
      "313 done\n",
      "352 done\n",
      "359 done\n",
      "360 done\n",
      "381 done\n",
      "603 done\n",
      "654 done\n",
      "655 done\n",
      "656 done\n",
      "662 done\n",
      "664 done\n",
      "677 done\n",
      "683 done\n",
      "714 done\n",
      "724 done\n",
      "749 done\n",
      "783 done\n",
      "json info dump done\n"
     ]
    }
   ],
   "source": [
    "for d in documents:\n",
    "    text,info = parse_document(d)\n",
    "    with open(f'data/KR_{d}.txt','w+',encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    documents_info[d] = info\n",
    "    print(f'{d} done')\n",
    "with open('data/documents_info.json','w+',encoding='utf-8') as f:\n",
    "    json.dump(documents_info,f)\n",
    "print('json info dump done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<id>654</id>:\n",
      "<title>Внебольничная пневмония у взрослых</title>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(documents_info['654'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://apicr.minzdrav.gov.ru/api.ashx?op=GetClinrec2&id={381}&ssid=undefined'\n",
    "request = requests.get(url)\n",
    "\n",
    "data = request.json()['obj']['sections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = data[find_by_element_by_id(data,'doc_crat_info_1_4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(content['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Острый бронхит (J20)\n",
      "J20.0 — Острый бронхит, вызванный Mycoplasma pneumoniae\n",
      "J20.1 — Острый бронхит, вызванный Haemophilus influenzae (палочкой Афанасьева-Пфейффера)\n",
      "J20.2 — Острый бронхит, вызванный стрептококком\n",
      "J20.3 — Острый бронхит, вызванный вирусом Коксаки\n",
      "J20.4 — Острый бронхит, вызванный вирусом парагриппа\n",
      "J20.5 — Острый бронхит, вызванный респираторным синцитиальным вирусом\n",
      "J20.6 — Острый бронхит, вызванный риновирусом\n",
      "J20.7 — Острый бронхит, вызванный эховирусом\n",
      "J20.8 — Острый бронхит, вызванный другими уточненными агентами\n",
      "J20.9 — Острый бронхит неуточненный\n",
      "J40 — Бронхит, не уточненный как острый или хронический\n",
      "J41 — Простой и слизисто-гнойный хронический бронхит\n",
      "J42 — Хронический бронхит неуточненный\n"
     ]
    }
   ],
   "source": [
    "print(soup.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J30.1 – Аллергический ринит, вызванный пыльцой растений\n",
      "J30.2 – Другие сезонные аллергические риниты\n",
      "J30.3 – Другие аллергические риниты\n",
      "J30.4 – Аллергический ринит неуточненный\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(find_diseases_in_content(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
